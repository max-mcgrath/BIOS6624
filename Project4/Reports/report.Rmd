---
title: "Project 4 Report"
author: |
    | Analyst: Max McGrath
    | Investigator: Nichole Carlson
    | Report generated: `r format(Sys.Date(), '%m/%d/%Y')`
header-includes:
    - \usepackage{setspace}\doublespacing
    - \usepackage{titling}
    - \usepackage{fixmath}
    - \usepackage{amsmath}
output: pdf_document
indent: true
mainfont: Times New Roman
fontsize: 12pt
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.kable.NA = "-")
library(kableExtra)
library(janitor)
setwd("..")
source("Code/5_SimAnalysis1a.R")
source("Code/6_MakeTables1a.R")
```

\newpage

## Introduction

This study aims to investigate the efficacy of several model selection 
techniques for linear regression across four case scenarios. More specifically,
it aims to evaluate the ability of a set of backwards selection and
regularization techniques to select models that retain significant predictors
and remove insignificant predictors across scenarios with varying sample sizes
and correlation structures between predictors. To do so, simulation will
be used to create regression data sets with known underlying models, then each 
model selection technique will be applied to each data set to build a model. 
Each model selection technique's performance will then be evaluated using
a number of criteria that quantify the technique's overall ability to identify 
significant predictors and to accurately estimate those predictors' known 
associations with the response.

Potential hypotheses:

 - Refitting after doing LASSO and EN will lead to a high FPR
 - AIC will have a higher TPR at the cost of a higher FPR relative to BIC

## Methods

### Simulation

For all case scenarios, 1000 data sets will be simulated from the model
$$
y_i=\beta_1x_{1,i}+\beta_2x_{2,i}+\cdots+\beta_{20}x_{20,i}+\epsilon_i.
$$
where $\{\beta_1,...,\beta_5\}=\{\frac{1}{6},\frac{1}{3},\frac{1}{2},\frac{2}{3},\frac{5}{6}\}$, 
$\beta_6,\ldots,\beta_{20}$ are equal to 0, and $\epsilon_i\sim{N(0,1)}$. The
data sets for the four case scenarios will then differ based on sample size, $N$, and correlation 
structure as follows: (1a) $N=250$ and all predictors are indepdendent, (1b)
$N=250$ and predictors have an exchangeable correlation coefficient of $0.4$,
(2a) $N=500$ and all predictors are indepdendent, and (2b)
$N=500$ and predictors have an exchangeable correlation coefficient of $0.4$.
All data will be generated using the `genData` R package.

### Backwards Selection

For each data set, we will then apply model selection techniques including
three backwards selection techniques and two regularization methods and record
which predictors are retained in each final model along with estimated 
coefficients and any other relevant statistics. For backwards selection,
we will three techniques with differing predictor retention criteria. For the
first, predictors will be removed one at a time according to highest p-value
until all predictors have a p-value under $0.15$. For the second and third,
we will use AIC and BIC, respectively, to iteratively reduce the model until
the respective information criteria no longer decreases as predictors are 
removed. 

### Regularization

For regularization, we will use LASSO and Elastic Net, each with both
a fixed regularization parameter and with regularization parameters selected using 
cross-validation. For Elastic Net, the penalization mixing parameter will
be fixed at $0.5$. 

### Evaluation

After applying each model selection technique to each of the 1000 simulated 
data sets for each of the case scenarios, technique performance will be
evaluated and summarized. Table 1 provides an example of the statistics calculated
for each model building technique for case scenario 1a. A similar table will
be created for each case scenario, and the results of the technique evaluations
will be discussed.

## Results



\newpage

```{r, echo = FALSE}
kable(bind_rows(modelDF, coefDF), booktabs = TRUE, 
      caption = "Model Summary - Case 1a", 
      digits = 3,
      col.names = c("", "P-Val", "AIC", "BIC", "LASSO",
                "LASSO with CV", "Elastic Net", "EN with CV"),
      escape = FALSE) %>%
    kable_styling(latex_options = c("scale_down")) %>%
    pack_rows("Full Model", 1, 5, escape = FALSE, bold = FALSE) %>%
    pack_rows("$\\beta_1=1/6$", 6, 8, escape = FALSE) %>%
    pack_rows("$\\beta_2=1/3$", 9, 11, escape = FALSE) %>%
    pack_rows("$\\beta_3=1/2$", 12, 14, escape = FALSE) %>%
    pack_rows("$\\beta_4=2/3$", 15, 17, escape = FALSE) %>%
    pack_rows("$\\beta_5=5/6$", 18, 20, escape = FALSE) %>%
    column_spec(c(1), border_right = TRUE, width = "1.2in")  %>%
    add_header_above(c(" " = 1, "Backwards Selection" = 3, "Regularization" = 4))
```